{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ray Distributed Objects and a Comparison to Parsl and FuncX.\n",
    "this is the actor demo from the blog post "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several utility functions that handle the topic and subtopic recognition for the titles from ArXiv.\n",
    "For example,\n",
    "\n",
    "'Spectral Measures on Locally Fields [math.FA]'\n",
    "\n",
    "comes from the top level topic math and the subtopic FA  which among the ArXiv categories we call Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_config(subj, basepath):\n",
    "    docpath =basepath+ \"/config_\"+subj+\".json\"\n",
    "    with open(docpath, 'rb') as f:\n",
    "        doc = f.read() \n",
    "    z =json.loads(doc)\n",
    "    subject = z['subject']\n",
    "    loadset = z['loadset']\n",
    "    subtopics = []\n",
    "    for w in z['supertopics']:\n",
    "        subtopics.extend([(w[0], w[1])])\n",
    "    return subject, loadset, subtopics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(subtopics):\n",
    "    dic = {}\n",
    "    for main in subtopics:\n",
    "        sl = main[1]\n",
    "        for x in sl:\n",
    "            dic[x] = main[0]\n",
    "    return dic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split_titles is the most important library function.   it is the one that given a title, and a general topic it returns the correct subtopic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_titles(topic, disp_title):\n",
    "    subject,loadset, subtopics = read_config(topic,\"../scdoc-new\")\n",
    "    dic = make_dict(subtopics)\n",
    "    toplist = [subtopics[i][0] for i in range(len(subtopics))]\n",
    "    lis = []\n",
    "    for ti in disp_title:\n",
    "        l = ti.find('[')\n",
    "        if(l >= 0):\n",
    "            e = ti[l+1:]\n",
    "            l2 = e.find(']')\n",
    "            e = e[:l2]\n",
    "            try:\n",
    "                i = 0\n",
    "                for x in toplist:\n",
    "                    if dic[e] == x:\n",
    "                        return x\n",
    "                    i = i+1\n",
    "            except:\n",
    "                print('ti', e)\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'analysis'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = 'Spectral Measures on Locally Fields [math.FA]'\n",
    "split_titles('math', [x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when split_titles is called with \"all4\" as the topic it returns the toplevel category for the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'math'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_titles('all4', [x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subclassifier generates an actor for each of the top level categories.  this actor stores titles in lists for each subcategory of that top level topic\n",
    "\n",
    "compute_subclass is our dummy worker function that takes a pointer to a subclass actor and a title and pushes it to the subclass actor\n",
    "\n",
    "Classifier creates an actor that sorts sentences by toplevel category and launches an invocation of compute_subclass for it.\n",
    "\n",
    "More details in the blog post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class SubClassifier:\n",
    "    def __init__(self, topic):\n",
    "        self.topic = topic\n",
    "        subject,loadset, subtopics = read_config(topic,\"./\")\n",
    "        toplist = [subtopics[i][0] for i in range(len(subtopics))]\n",
    "        self.topics = {top:[] for top in toplist}\n",
    "        self.counter = {top:0 for top in toplist}\n",
    "        \n",
    "    def send(self, title):\n",
    "        subt = split_titles(self.topic,  [title])\n",
    "        self.topics[subt].append(title)\n",
    "        self.counter[subt]+=1\n",
    "        return subt\n",
    "    \n",
    "    def get_classification(self):\n",
    "        return self.topics, self.counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the parameter for sleep below is how we adjust the amount of \"work\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def compute_subclass(subc_ptr, title):\n",
    "    time.sleep(3.0)\n",
    "    fut =  subc_ptr.send.remote(title)\n",
    "    return fut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue_size = 0 #this size yields sequential execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "class Classifier:\n",
    "    def __init__(self, topic):\n",
    "        self.topic = topic\n",
    "        self.future_list = []\n",
    "        self.future_count =  0\n",
    "    def send(self, title):\n",
    "        subt = split_titles(self.topic, [title])\n",
    "        if subt != '':\n",
    "            try:\n",
    "                cl = ray.get_actor(subt)\n",
    "            except:\n",
    "                cl = SubClassifier.options(name=subt, lifetime=\"detached\").remote(subt)\n",
    "            \n",
    "            self.future_list.append(compute_subclass.remote(cl, title))\n",
    "            if self.future_count < queue_size:\n",
    "                self.future_count +=1\n",
    "            else:\n",
    "                for x in self_future_list:\n",
    "                    ray.get(x)\n",
    "                self.future_list = []\n",
    "                self.future_count = 0\n",
    "        return \"item sent to subcategory\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Server is the backend class for the serve client.    it sends the document to the classifier object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self):\n",
    "        self.counter = 0\n",
    "        try:\n",
    "            cl = ray.get_actor('all4')\n",
    "            print(cl)\n",
    "        except:\n",
    "            cl = Classifier.options(name='all4', lifetime=\"detached\").remote('all4')\n",
    "        self.classifier = cl\n",
    "\n",
    "    async def __call__(self, starlette_request):\n",
    "        payload_bytes = await starlette_request.body()\n",
    "        arg = payload_bytes.decode(\"utf-8\")\n",
    "        v = ray.get(self.classifier.send.remote(arg))\n",
    "        return {'status':v}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-03-26 10:53:45,166\tINFO services.py:1172 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    }
   ],
   "source": [
    "from ray import serve\n",
    "import requests\n",
    "\n",
    "client = serve.start(http_options={\"host\":'0.0.0.0'})\n",
    "client.create_backend(\"sciml:v0\", Server)\n",
    "client.create_endpoint(\n",
    "    \"classify\",\n",
    "    backend=\"sciml:v0\",\n",
    "    route=\"/classify\",\n",
    "    methods=[\"POST\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=17905)\u001b[0m 2021-03-19 17:59:33,566\tINFO router.py:249 -- Endpoint classify doesn't exist, waiting for registration.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'analysis'}\n"
     ]
    }
   ],
   "source": [
    "sent = 'Spectral Measures on Locally Fields [math.FA]'\n",
    "resp = requests.post(\n",
    "    \"http://44.234.63.1:8000/classify\", data=sent)\n",
    "print(resp.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the code in a cluster the actors are persistent.   here is a way to see their contents and (if uncommented) kill each one.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic = physics number = 62\n",
      "topic = math number = 28\n",
      "topic = bio number = 11\n",
      "topic = compsci number = 32\n",
      "topic = finance number = 7\n",
      "total = 140\n"
     ]
    }
   ],
   "source": [
    "subject,loadset, subtopics = read_config('all4',\"./\")\n",
    "dic = make_dict(subtopics)\n",
    "toplist = [subtopics[i][0] for i in range(len(subtopics))]\n",
    "total =  0\n",
    "for top in toplist:\n",
    "    try:\n",
    "        sub,loads, subtop = read_config(top,\"./\")\n",
    "        stoplist = [subtop[i][0] for i in range(len(subtop))]\n",
    "        actor = ray.get_actor(top)\n",
    "        l = ray.get(actor.get_classification.remote())\n",
    "        local_tot =  0\n",
    "        for t in stoplist:\n",
    "            local_tot += l[1][t]\n",
    "        total += local_tot\n",
    "        print('topic =', top, 'number =', local_tot)\n",
    "        #print(l)\n",
    "        #ray.kill(actor)\n",
    "    except:\n",
    "        print('no actor for topic ', top)\n",
    "print('total =', total)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    actor = ray.get_actor('all4')\n",
    "    ray.kill(ray.get_actor('all4'))\n",
    "except:\n",
    "    print('no all4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
